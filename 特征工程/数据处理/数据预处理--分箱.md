## 变量分箱（即变量离散化）：  
分箱就是将**连续变量离散化**、**将多状态的离散变量合并成少状态**。

&nbsp;
## 三类变量分箱方法：
### 1.无序变量分箱 
“一位有效编码” （one-hot Encoding），通常叫做虚变量或者哑变量（dummpy variable）。  
在模型中引入多个虚拟变量时，虚拟变量的个数应按下列原则确定：  
a)回归模型有截距：一般的，若该特征下n个属性均互斥（如，男/女;儿童/青年/中年/老年），在生成虚拟变量时，应该生成 n-1个虚变量，这样可以避免产生多重共线性。  
b)回归模型无截距项：有n个特征，设置n个虚拟变量  

### 2.有序变量分箱 
在变量中有多个可能会出现的取值，各取值之间还存在等级关系。  
使用 pandas 中的 map（）替换相应变量就行。  

### 3.连续变量的分箱方式:无监督分组、有监督分组 
a）常用的无监督分箱方法有等频分箱，等距分箱和聚类分箱。  
b）有监督分箱主要有best-ks分箱和卡方分箱。  

### 卡方分箱的原理  
卡方分箱是自底向上的(即基于合并的)数据离散化方法。  
它依赖于卡方检验:具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。   
基本思想:对于精确的离散化，相对类频率在一个区间内应当完全一致。  
因此,如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；  
否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。   

&nbsp;
## 注意问题 
对于分箱需要注意的是，分完箱之后，某些箱区间里，bad或者good分布比例极不均匀，极端时，会出现bad或者good数量直接为0。那么这样子会直接导致后续计算WOE时出现inf无穷大的情况，这是不合理的。这种情况，说明分箱太细，需要进一步缩小分箱的数量。  

&nbsp;
## reference
[数据预处理——数据分箱](https://zhuanlan.zhihu.com/p/52312186)  
[特征工程之分箱--卡方分箱](https://www.cnblogs.com/wqbin/p/10547167.html)  
[评分卡入门与创建原则——分箱、WOE、IV、分值分配](https://blog.csdn.net/sscc_learning/article/details/78591210)

