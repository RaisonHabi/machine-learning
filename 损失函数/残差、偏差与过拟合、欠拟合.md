### 残差
残差在数理统计中是**指实际观察值与估计值（拟合值）之间的差**。  
“残差”蕴含了有关模型基本假设的重要信息。如果回归模型正确的话， 我们可以将残差看作误差的观测值。

它应符合模型的假设条件，且具有误差的一些性质。利用残差所提供的信息，来考察模型假设的合理性及数据的可靠性称为残差分析。

**残差是指预测值与实际值的差**，由于残差的计算要用到全部观测，因此残差之间并不是相互独立的，同时，残差的标准差也不完全相同，越是异常值的点，其对应的残差的波动性越小。

### 偏差
**期望输出与真实标记的差别称为偏差（bias）**      
**偏差的含义：偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力**。

在数学和统计学中，偏差是**变量的观测值与其他某个值（通常是该变量的平均值）之间差异的度量**。偏差的符号表示差异的方向。值的大小表示差异的大小。

### 方差
Variance是不同的训练数据集训练出的模型输出值之间的差异  
使用样本数相同的不同训练集产生的方差     
**方差的含义：方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响**。

方差是在概率论和统计方差**衡量随机变量或一组数据时离散程度的度量**。 概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。 统计中的方差（样本方差）是每个样本值与全体样本值的平均数之差的平方值的平均数。

##  偏差、方差窘境
一般来说，偏差与方差是有冲突的，这称为偏差-方差窘境（bias-variance dilemma）。  
下图给出了一个示意图.   
给定学习任务，假定我们能控制学习算法的训练程度，则**在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率**；

**随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率**；

**在训练程度充足后，学习器的拟合能力已经非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合**。

<figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-7f56516f55463656e81d55edc5c069e8_b.jpg" data-size="normal" data-rawwidth="572" data-rawheight="425" class="origin_image zh-lightbox-thumb" width="572" data-original="https://pic1.zhimg.com/v2-7f56516f55463656e81d55edc5c069e8_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;572&#39; height=&#39;425&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="572" data-rawheight="425" class="origin_image zh-lightbox-thumb lazy" width="572" data-original="https://pic1.zhimg.com/v2-7f56516f55463656e81d55edc5c069e8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-7f56516f55463656e81d55edc5c069e8_b.jpg"/><figcaption>泛化误差与偏差、方差的关系示意图</figcaption></figure>

&nbsp;
## 偏差、方差与过拟合、欠拟合的关系？
**一般来说，简单的模型会有一个较大的偏差和较小的方差，复杂的模型偏差较小方差较大**。

**欠拟合：模型不能适配训练样本，有一个很大的偏差**。

举个例子：我们可能有本质上是多项式的连续非线性数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据不重要，因为模型根本无法表示数据的基本关系，模型不能适配训练样本，有一个很大的偏差，因此我们需要更复杂的模型。那么，是不是模型越复杂拟合程度越高越好呢？也不是，因为还有方差。

**过拟合：模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差**。

方差就是指模型过于拟合训练数据，以至于没办法把模型的结果泛化。而泛化正是机器学习要解决的问题，如果一个模型只能对一组特定的数据有效，换了数据就无效，我们就说这个模型过拟合。这就是模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。

&nbsp;
## 偏差、方差与模型复杂度的关系
由前面偏差和方差的介绍，我们来总结一下偏差和方差的来源：我们训练的机器学习模型，必不可少地对数据依赖。但是，如果你不清楚数据服从一个什么样的分布，或是没办法拿到所有可能的数据（肯定拿不到所有数据），那么我们训练出来的模型和真实模型之间存在不一致性。这种不一致性表现在两个方面：偏差和方差。

那么，既然偏差和方差是这么来的，而且还是无法避免的，那么我们有什么办法尽量减少它对模型的影响呢？

一个好的办法就是正确选择模型的复杂度。复杂度高的模型通常对训练数据有很好的拟合能力，但是对测试数据就不一定了。而复杂度太低的模型又不能很好的拟合训练数据，更不能很好的拟合测试数据。因此，模型复杂度和模型偏差和方差具有如下图所示关系。

<figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-1c8804f2885d07958a55c50164e74b43_b.jpg" data-caption="" data-size="normal" data-rawwidth="462" data-rawheight="295" class="origin_image zh-lightbox-thumb" width="462" data-original="https://pic4.zhimg.com/v2-1c8804f2885d07958a55c50164e74b43_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;462&#39; height=&#39;295&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="462" data-rawheight="295" class="origin_image zh-lightbox-thumb lazy" width="462" data-original="https://pic4.zhimg.com/v2-1c8804f2885d07958a55c50164e74b43_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-1c8804f2885d07958a55c50164e74b43_b.jpg"/></figure>

&nbsp;
### 误差
Bias和Variance是针对Generalization（一般化，泛化）来说的：
```
- 偏差bias: 描述模型输出结果的期望（均值）与样本真实结果的差距。 

- 方差variance: 描述模型对于给定值的输出稳定性。
```
误差error：generalization error=Bias^2+Variance

&nbsp;
## 偏差、方差与bagging、boosting的关系？
Bagging算法是对训练样本进行采样，产生出若干不同的子集，再从每个数据子集中训练出一个分类器，取这些分类器的平均，所以是降低模型的方差（variance）。Bagging算法和Random Forest这种并行算法都有这个效果。

Boosting则是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行权重调整，所以随着迭代不断进行，误差会越来越小，所以模型的偏差（bias）会不断降低

&nbsp;
## 偏差、方差和K折交叉验证的关系？
K-fold Cross Validation的思想：将原始数据分成K组(一般是均分)，将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标。

对于一系列模型[公式], 我们使用Cross Validation的目的是获得预测误差的无偏估计量CV，从而可以用来选择一个最优的Theta*,使得CV最小。假设K-folds cross validation，CV统计量定义为每个子集中误差的平均值，而K的大小和CV平均值的bias和variance是有关的：
[公式]
其中，m = N/K 代表每个子集的大小， N是总的训练样本量，K是子集的数目。

当K较大时，m较小，模型建立在较大的N-m上，经过更多次数的平均可以学习得到更符合真实数据分布的模型，Bias就小了，但是这样一来模型就更加拟合训练数据集，再去测试集上预测的时候预测误差的期望值就变大了，从而Variance就大了；k较小的时候，模型不会过度拟合训练数据，从而Bias较大，但是正因为没有过度拟合训练数据，Variance也较小。

&nbsp;
## 如何解决偏差、方差问题？
整体思路：首先，要知道偏差和方差是无法完全避免的，只能尽量减少其影响。
（1）在避免偏差时，需尽量选择正确的模型，一个非线性问题而我们一直用线性模型去解决，那无论如何，高偏差是无法避免的。

（2）有了正确的模型，我们还要慎重选择数据集的大小，通常数据集越大越好，但大到数据集已经对整体所有数据有了一定的代表性后，再多的数据已经不能提升模型了，反而会带来计算量的增加。而训练数据太小一定是不好的，这会带来过拟合，模型复杂度太高，方差很大，不同数据集训练出来的模型变化非常大。

（3）最后，要选择合适的模型复杂度，复杂度高的模型通常对训练数据有很好的拟合能力。

针对偏差和方差的思路：
```
偏差：实际上也可以称为避免欠拟合。
1、寻找更好的特征 -- 具有代表性。
2、用更多的特征 -- 增大输入向量的维度。（增加模型复杂度）
方差：避免过拟合
1、增大数据集合 -- 使用更多的数据，减少数据扰动所造成的影响
2、减少数据特征 -- 减少数据维度，减少模型复杂度
3、正则化方法
4、交叉验证法
```

&nbsp;
## reference
[偏差（Bias）与方差（Variance）](https://zhuanlan.zhihu.com/p/38853908)

维基百科
