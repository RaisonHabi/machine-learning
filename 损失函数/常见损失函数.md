## 损失函数
损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。

**损失函数分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项**。

常见的损失函数以及其优缺点如下：
### 1.0-1损失函数(zero-one loss)
<p>0-1损失是指预测值和目标值不相等为1， 否则为0:</p><p><img src="https://www.zhihu.com/equation?tex=L+%28+Y+%2C+f+%28+X+%29+%29+%3D+%5Cleft%5C%7B+%5Cbegin%7Barray%7D+%7B+l+%7D+%7B+1+%2C+Y+%5Cneq+f+%28+X+%29+%7D+%5C%5C+%7B+0+%2C+Y+%3D+f+%28+X+%29+%7D+%5Cend%7Barray%7D+%5Cright.+++%5C%5C" alt="L ( Y , f ( X ) ) = \left\{ \begin{array} { l } { 1 , Y \neq f ( X ) } \\ { 0 , Y = f ( X ) } \end{array} \right.   \\" eeimg="1"/> </p><p> 特点：</p><p>(1)0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用.</p>

<p>(2)<b>感知机</b>就是用的这种损失函数。但是相等这个条件太过严格，因此可以放宽条件，即满足 <img src="https://www.zhihu.com/equation?tex=%7CY+-+f%28x%29%7C+%3C+T" alt="|Y - f(x)| &lt; T" eeimg="1"/> 时认为相等，</p><p><img src="https://www.zhihu.com/equation?tex=L+%28+Y+%2C+f+%28+X+%29+%29+%3D+%5Cleft%5C%7B+%5Cbegin%7Barray%7D+%7B+l+%7D+%7B+1+%2C+%7C+Y+-+f+%28+X+%29+%7C+%5Cgeq+T+%7D+%5C%5C+%7B+0+%2C+%7C+Y+%3D+f+%28+X+%29+%7C+%3C+T+%7D+%5Cend%7Barray%7D+%5Cright.++%5C%5C" alt="L ( Y , f ( X ) ) = \left\{ \begin{array} { l } { 1 , | Y - f ( X ) | \geq T } \\ { 0 , | Y = f ( X ) | &lt; T } \end{array} \right.  \\" eeimg="1"/> </p>

### 2.绝对值损失函数
绝对值损失函数是计算预测值与目标值的差的绝对值：  
<p><img src="https://www.zhihu.com/equation?tex=L%28Y%2C+f%28x%29%29+%3D+%7CY+-+f%28x%29%7C++%5C%5C" alt="L(Y, f(x)) = |Y - f(x)|  \\" eeimg="1"/> </p>

### 3.log对数损失函数
log对数损失函数的标准形式如下：  
<p><img src="https://www.zhihu.com/equation?tex=L%28Y%2C+P%28Y%7CX%29%29+%3D+-logP%28Y%7CX%29++%5C%5C" alt="L(Y, P(Y|X)) = -logP(Y|X)  \\" eeimg="1"/> </p><p>特点：</p><p>(1) log对数损失函数能非常好的表征概率分布，在很多场景尤其是多分类，如果需要知道结果属于每个类别的置信度，那它非常适合。</p><p>(2)健壮性不强，相比于hinge loss对噪声更敏感。</p><p>(3)<b>逻辑回归</b>的损失函数就是log对数损失函数。</p>

### 4.平方损失函数
平方损失函数标准形式如下：   
<p><img src="https://www.zhihu.com/equation?tex=L+%28+Y+%7C+f+%28+X+%29+%29+%3D+%5Csum+_+%7B+N+%7D+%28+Y+-+f+%28+X+%29+%29+%5E+%7B+2+%7D++%5C%5C" alt="L ( Y | f ( X ) ) = \sum _ { N } ( Y - f ( X ) ) ^ { 2 }  \\" eeimg="1"/> </p><p>特点：</p><p>(1)经常应用与回归问题</p>

### 5.指数损失函数（exponential loss）
指数损失函数的标准形式如下：   
<p><img src="https://www.zhihu.com/equation?tex=L%28Y%7Cf%28X%29%29+%3D+exp%5B-yf%28x%29%5D++%5C%5C" alt="L(Y|f(X)) = exp[-yf(x)]  \\" eeimg="1"/> </p><p>特点：</p><p>(1)对离群点、噪声非常敏感。经常用在AdaBoost算法中。</p>

### 6.Hinge 损失函数
Hinge损失函数标准形式如下：   
<p><img src="https://www.zhihu.com/equation?tex=L%28y%2C+f%28x%29%29+%3D+max%280%2C+1-yf%28x%29%29+++%5C%5C" alt="L(y, f(x)) = max(0, 1-yf(x))   \\" eeimg="1"/> </p><p> 特点：</p><p>(1)hinge损失函数表示如果被分类正确，损失为0，否则损失就为 <img src="https://www.zhihu.com/equation?tex=1-yf%28x%29" alt="1-yf(x)" eeimg="1"/> 。<b>SVM</b>就是使用这个损失函数。</p><p>(2)一般的 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="f(x)" eeimg="1"/> 是预测值，在-1到1之间， <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 是目标值(-1或1)。其含义是， <img src="https://www.zhihu.com/equation?tex=f%28x%29+" alt="f(x) " eeimg="1"/> 的值在-1和+1之间就可以了，并不鼓励 <img src="https://www.zhihu.com/equation?tex=%7Cf%28x%29%7C+%3E+1" alt="|f(x)| &gt; 1" eeimg="1"/> ，即并不鼓励分类器过度自信，让某个正确分类的样本距离分割线超过1并不会有任何奖励，从而<b>使分类器可以更专注于整体的误差。</b></p><p>(3) 健壮性相对较高，对异常点、噪声不敏感，但它没太好的概率解释。</p>

### 7.感知损失(perceptron loss)函数
感知损失函数的标准形式如下：   
<p><img src="https://www.zhihu.com/equation?tex=L%28y%2C+f%28x%29%29+%3D+max%280%2C+-f%28x%29%29++%5C%5C" alt="L(y, f(x)) = max(0, -f(x))  \\" eeimg="1"/> </p><p>特点：</p><p>(1)是Hinge损失函数的一个变种，Hinge loss对判定边界附近的点(正确端)惩罚力度很高。而perceptron loss<b>只要样本的判定类别正确的话，它就满意，不管其判定边界的距离</b>。它比Hinge loss简单，因为不是max-margin boundary，所以模<b>型的泛化能力没 hinge loss强</b>。</p>



&nbsp;
## reference
[常见的损失函数(loss function)总结](https://zhuanlan.zhihu.com/p/58883095)  
[机器学习--LR逻辑回归与损失函数理解](https://blog.csdn.net/u014106644/article/details/83660226)
