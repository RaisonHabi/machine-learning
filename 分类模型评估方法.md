## 背景：  
在模型建立之后，必须对模型的效果进行评估，因为数据挖掘是一个探索的过程，评估-优化是一个永恒的过程。

### scikit的classifier.predict()默认使用0.5?  
这是数学观点上唯一明智的门槛

## 混淆矩阵： 
TP（实际为正预测为正），FP（实际为负但预测为正），TN（实际为负预测为负），FN（实际为正但预测为负）  
**查全率（召回率，recall）：**
查全率＝ TP / (TP+FN)  
**查准率（精准率，Precision）：**
查准率＝ TP / (TP+FP)  
**准确率：**
Accuracy=(TP+TN) / (TP+FP+TN+FN)  
**阴性预测值：**
可以理解为负样本的查准率，计算公式：
NPV=TN / (TN+FN)  

*查准率和查全率通常是一对矛盾的度量，通常一个高，另外一个就低。两个指标都很重要，如何综合考虑这两个指标呢？*  
主要有两种办法:  
1."平衡点“(Break-Even Point, BEP):查准率=查全率的点;  
2. F1度量---查准率和查全率的加权调和平均数.  

## ROC、AUC:
ROC曲线描绘的是不同的**阈值**时，并以FPR和TPR为横纵坐标轴，描述随着截断点的变小，TPR随着FPR的变化。  
纵轴：TPR(true postive rate)=正例分对的概率 = TP/(TP+FN)，其实就是查全率  
横轴：FPR=负例分错的概率 = FP/(FP+TN)  
判断标准：  
1.一个ROC曲线完全”包住“另一个ROC曲线--->第一个学习器效果更好  
2.两个ROC曲线相交--->利用ROC曲线下的面积（AUC，area under ROC curve，是一个数值)进行比较  
***auc的意义：***  
**AUC表示，任取一对正负例，分类器给出正例得分大于负例得分的概率**  
[理解AUC](https://www.cnblogs.com/van19/p/5494908.html)  

## KS: 
KS曲线和ROC曲线都用到了TPR，FPR。KS曲线是把TPR和FPR都作为纵坐标，而样本数作为横坐标。  
*好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。*   
KS的计算步骤如下：   
1.计算每个评分区间的好坏账户数。   
2.计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。   
3.计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。

## GINI系数(洛伦兹曲线): 


## Lift: 
Lift图衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。  
Lift=(TP/(TP+FP))/(P/(P+N))  

## Gain: 
Gain图是描述整体精准度的指标。Gain=TP/(TP+FP)  

## PSI:  
群体稳定性指标PSI(Population Stability Index)是衡量模型的预测值与实际值偏差大小的指标。  
PSI = sum（（实际占比-预期占比）* ln（实际占比/预期占比））  







## reference
[分类模型的评价指标--混淆矩阵，ROC，AUC，KS，Lift，Gain](https://blog.csdn.net/shy19890510/article/details/79501582)  
[神秘的KS值和GINI系数](https://blog.csdn.net/u013421629/article/details/78217498)  
