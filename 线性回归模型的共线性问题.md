**线性回归模型的多重共线性问题**  
共线性，指多元回归模型中，各自变量之中至少有两个完全或高度相关。  
自变量之间的强相关，可能导致回归系数的正负方向与真实的相反，影响特征的可解释性。  
可以认为 LR 来源于多元回归，将元与特征，自变量与特征，回归系数与权重一一对应就可以啦。  
***示例：***  
首先，将问题推向极端，假设存在两个线性相关的特征 x1 和 x2，有 y = w1*x1 + w2*x2 + others。如果 x1 和 x2 分别代表速度特征 m/s 和 km/h，即 x2 = 3.6 * x1，则 y = (w1+3.6*w2)x1 + others。如果理论上速度和 y 的关系是 7 倍，即最优解 w1+3.6*w2 = 7。来看看寻找这个最优解时会发生什么。  
一方面，值更大的特征对应的 w2 的变动对 7 的影响要大于值更小的特征对应的 w1 的变动。优化过程中，w2 的变化使得 w1 产生较大的变化，可能会出现，w1 变成负值的情况。  
可是前面说过 y 和速度是正相关的，如此以来，x1 与 y 成了负相关，显然有悖现实。当我们用权重来解释特征影响时，这会造成误解。

**造成多重共线性的原因：**  
1、解释变量都享有共同的时间趋势；  
2、一个解释变量是另一个的滞后，二者往往遵循一个趋势；  
3、由于数据收集的基础不够宽，某些解释变量可能会一起变动；  
4、某些解释变量间存在某种近似的线性关系；

**判别：**  
1、发现系数估计值的符号不对；  
2、某些重要的解释变量t值低，而R方不低   
3、当一不太重要的解释变量被删除后，回归结果显著变化；

**检验：**  
1、相关性分析，相关系数高于0.8，表明存在多重共线性；但相关系数低，并不能表示不存在多重共线性；  
2、vif检验；  
3、条件系数检验；

**解决方法：**  
1、增加数据；  
2、对模型施加某些约束条件；  
3、删除一个或几个共线变量；  
4、将模型适当变形；  
5、主成分回归  

**处理多重共线性的原则：**  
1、  多重共线性是普遍存在的，轻微的多重共线性问题可不采取措施；  
2、  严重的多重共线性问题，一般可根据经验或通过分析回归结果发现。如影响系数符号，重要的解释变量t值很低。要根据不同情况采取必要措施。  
3、  如果模型仅用于预测，则只要拟合程度好，可不处理多重共线性问题，存在多重共线性的模型用于预测时，往往不影响预测结果；



**reference**  
[逻辑斯蒂回归中特征共线性或强相关的影响](https://blog.csdn.net/lipengcn/article/details/82467082)  
[多重共线性的产生原因、判别、检验、解决方法](https://blog.csdn.net/diyiziran/article/details/17025471)
