## 内容详见链接,尤其是图片，总结的很棒
## 一、系统概述
```
资源池：存储各种类型的海量资源，一般由数据库存储，如 mysql、hive、redis 等。
标签生成：标签是对资源更多维度的结构化刻画。比如：分类标签、关键词、质量分等。
索引：对资源的各类标签、关键词建立倒排索引，及相似向量检索引擎等。
过滤：对用户的曝光历史、负反馈等进行过滤。
召回：使用用户画像标签或用户 Embedding 到索引和向量库中获取相关的候选资源。
用户画像：用户属性及根据用户的历史行为给用户打的标签。
排序：通过模型对召回的每个候选资源进行预测打分。
特征 / 模型：排序依赖的用户特征、资源特征及模型。
运营：业务策略，包括提权、曝光占比控制、打散等业务策略。
输出：将排序及运营后的 topN 个资源打包返回给客户端。
```

&nbsp;
## 二、排序模型
### 1. 模型介绍
汽车之家首页推荐排序模型主要经历了 LR、XGBoost、FM、DeepFM、DeepFM Online Learning 这几个主要的演进过程，在这个过程中还实验了如 Wide&Deep、DCN、LSTM、GRU 等模型。

LR 模型是 CTR 预估领域早期最成功的模型，大多早期的工业推荐排序系统采取 LR 这种 “线性模型 + 人工特征组合引入非线性” 的模式。LR 模型具有训练快、上线快、可解释性强、容易上规模等优点，目前仍然有不少实际系统采取这种模式。同时 LR 模型也是之家推荐排序系统初期的验证模型和中后期的 baseline 模型。

XGBoost 模型在使用和 LR 相同的特征，上线后就取得了比较明显的效果，之后又增加了 user 和 item 的实时特征，实验组 CTR 得到了进一步的提升，总体上相对提升 6%。在和对照组持续观察了 3 周后，XGBoost 的提升效果得到了验证，替换了 LR 成为线上的全量模型和 baseline 模型。之后还尝试了 XGBoost+LR，效果相比 XGBoost 没有明显提升。

FM 简洁优雅地实现了二阶特征组合。实现特征组合比较容易想到的是在 LR 的基础上加入二阶特征组合即可，即任意两个特征进行组合，将组合出的特征看作新特征，加到 LR 模型中。组合特征的权重在训练阶段学习获得。但这样对组合特征建模，泛化能力比较弱，尤其是在大规模稀疏特征存在的场景下。FM 模型也直接引入任意两个特征的二阶特征组合，但对于每个特征，学习一个大小为 k 的一维向量，两个特征 Xi和 Xj 的特征组合的权重值，通过特征对应的向量 Vi 和 Vj 的内积 <Vi , Vj> 来表示。这本质上是对特征进行 Embedding 化表征，和目前常见的各种实体 Embedding 本质思想是一样的。特征组合对于推荐排序是非常重要的，DNN 模型一样离不开特征组合这个特点，但 MLP 是种低效率地捕获特征组合的结构，所以排序相关的深度模型，基本都具有类似 FM 组合特征的部分。FM 模型实践阶段主要是增加了样本量由几千万到 3 亿，线上实验 CTR 对比 XGBoost 相对提升 2%，因为后续 DeepFM 很快上线，FM 并没有推全。

Wide&Deep 是推荐领域取得较大成功的最早期深度模型，由 Google 于 2016 年提出。Wide&Deep 模型包括 Wide 部分和 Deep 部分，Wide 部分为 LR，输入为 one-hot 后的离散型特征和等频分桶后的连续性特征，这部分可以对样本中特征与目标较为明显的关联进行记忆学习；Deep 部分为 MLP，输入为 Embedding 后的离散型特征和归一化后的连续型特征，可以泛化学习到样本中多个特征之间与目标看不到的潜在关联。使用 Wide&Deep 的另一个优势在于 Wide 部分的存在，可以沿用之前浅层学习的成果，尤其是特征工程部分。Wide&Deep 上线后 CTR 相对提升 3%，比同期上线的 DeepFM 低 0.5%，线上主要使用了 DeepFM 模型。

DeepFM 将 Wide&Deep 的 Wide 部分 LR 替换成 FM 来避免人工特征工程。DeepFM 相比 Wide&Deep 模型更能捕捉低阶特征信息。同时，Wide&Deep 部分的 Embedding 层需要针对 Deep 部分单独设计，而在 DeepFM 中，FM 和 Deep 部分共享 Embedding 层，FM 训练得到的参数既作为 wide 部分的输出，也作为 MLP 部分的输入。DeepFM 支持 end-end 训练，Embedding 和网络权重联合训练，无需预训练和单独训练。DeepFM 上线后 CTR 相对提升 3.49%，略好于同期上线的 Wide&Deep。在效果得到验证后推全了 DeepFM 模型，使其成为线上的全量模型和 baseline 模型。线上效果的提升带来的是推荐排序模型预测耗时的增加，为了保证不超过最大平响，在不明显提高模型 loss 的前提下，实验优化 Deep 部分的参数，包括减少 Embedding 的维度和隐藏层的神经元个数与层数等。通过部署模型上线后观察效果，模型预测的耗时随之减少，而且 CTR 也没有明显波动，依然明显高于对照组，说明深度学习的泛化能力较强，即便降低模型的神经网络配置，依然能较好地拟合样本。

与 Wide&Deep 和 DeepFM 类似，DCN 将 Wide 部分升级为 Cross 网络，Cross 网络一方面通过显式的高阶特征交叉，另一方面通过层与层之间拟合残差，能够更深入地挖掘出非线性特征组合与目标的关系，更快地达到稳定的拟合状态。在和 DeepFM 采用相同特征的情况下，实验 CTR 也和 DeepFM 持平。根据线上的迭代经验和业务特点，尝试优化了 DCN 的模型结构。在 DCN 原始的 Embedding and Stacking 层中，离散型特征在经过 Embedding 处理后，与连续型特征直接拼接在一起，统一输入进后面的网络，这样带来的不足是：虽然网络可以用显性和隐性的方式学习特征间的有效交叉，但缺少单个特征内部信息的挖掘，将这部分压力转移到了特征工程，从而增加了人工成本。基于充分利用每个特征，通过排序模型自适应学习到更多信息的考虑，尝试对所有特征分别进行扩展。在 DCN 的 Embedding and Stacking 层和网络层之间实验引入特征扩展层，将每个特征从原始的 1 维扩展到 n 维，与 Embedding 只对离散型特征处理不同，维度扩展也会处理连续性特征。扩展后的特征在伴随着维度增加的同时，会将更多自身信息输入到网络层参与高阶计算，与只使用原始特征相比，模型可以更深入利用已有特征，节约了特征工程的人工成本。通过离线实验，在采用相同特征的情况下，相较 DCN，基于特征扩展的 DCN 上线后实验 CTR 相对提升 1%。

在上述模型迭代的同时，还实验了 LSTM、GRU 等模型，LSTM 和 GRU 都是基于序列的 next click 模型，模型的结构很简单，对于一个 Session 中的点击序列 X=[X1,X2,X3…Xn-1,Xn]，依次将 X1,X2,…,Xn-1 输入到模型中，预测下一个被点击的是哪一个 Item。首先，序列中的每一个物品 Xt 被转换为 one-hot，随后转换成其对应的 embedding，经过 N 层隐含单元后，再经过一个全联接层得到下一次每个物品被点击的概率。这些模型的 CTR 都暂未明显好于 DeepFM，所以都还在实验阶段，没有成为线上主要模型。

在 DeepFM 和其他深度模型的实践中，比较容易犯的错误是不考虑特征组成和样本数量，直接暴力增加模型复杂度，从而导致训练时间骤增、模型文件变大和线上的预测时间更久，最终引起推荐系统服务超时。如果特征数量少、特征工程完善和样本选取合理，使用简单的深度学习模型反而能够达到更好的效果。

### 2. 在线学习
在线学习利用实时收集的用户反馈，实时更新模型参数进行预测，实时反馈用户行为变化带来的影响。在线学习相对离线学习可以理解为数据集无限大，时间序列无限长，利用样本数据流逐条更新模型，在线学习是 DeepFM 上线后在模型更新方面做的优化。之前的模型更新从一周到一天，为了模型能更快的学习到用户的实时行为，我们将模型的更新周期做到了分钟级。

这里主要有两部分工作，一是 Label 及特征的实时获取，二是模型的实时更新。

对于 Label 及特征的实时获取是通过每次请求的唯一标识 id 使用服务端 dump 的特征和客户端的 Label ( 曝光、点击 ) 进行 join 生成，这里要注意的是 Label 必须和当次请求的特征 join，如果特征数据在 Label 之后有更新，则会产生特征穿越的问题。

模型的实时更新是将实时获取的样本累积到一个 batch 后，就进行迭代更新，更新后的模型每隔 10 分钟往线上推一次。累计 10 分钟在保证捕获用户实时行为实效性的前提下，既可以降低工程实现难度，又可以降低样本的抖动影响，对样本不均衡的情况可以采取采样策略进行处理。

### 3. 排序服务
排序服务是以 API 的形式提供，其中：

输入：

Deviceid: 用户唯一标识，在服务内部通过此 id 获取用户的属性及行为特征。

Itemid: 这是对用户待排序的资源 id，在服务内部会获取到这些资源属性、热度、标签等信息。

Pvid: 当次请求的唯一标识，用于关联客户端和服务端的日志。

Model-name: 模型名称，指定选用哪个模型进行排序，排序服务提供了多个模型供选择。

Model-version: 模型版本，和 Model-name 搭配使用，指定同一个模型的哪个版本，这个参数主要用来进行模型迭代优化。

Debug: 此参数用来输出排序过程中的一些中间结果。

输出：Itemid 及其打分。

排序服务中的多个模型有不同的更新策略，更新周期可配置。排序服务还依赖于特征服务获取用户和资源的特征，对应到不同模型还有不同的特征工程处理。

### 4. 模型更新
实验的小流量排序模型经过离线验证，线上可以定时直接热更新。线上的全量排序模型更新除了离线验证外，还要在推全之前有一个预上线实验验证，确保在预上线实验组上 CTR 等数据没问题，再将模型全部更新。

### 5. AB 实验
在机器学习领域中，AB 实验是验证模型最终效果的主要手段。进行 AB 实验的主要手段是进行用户分桶，即将用户分成实验组和对照组，对实验组的用户施以新模型，对照组的用户施以旧模型。在分桶的过程中，要注意样本的独立性和采样方式的无偏性，确保同一个用户每次只能分到同一个桶中，在分桶过程中选取 DeviceId 必须是完全随机的，这样才能保证桶中的样本是无偏的。实验组和对照组的划分必须是在相同的约束条件下随机选取 DeviceId。如下图 a、b、c 的划分都不正确，其中 a 中实际划分的用户超出了实验约束的用户群，b 中实验组用户正确，但是把剩余的所有用户作为对照组是不对的，c 中实验用户正确，对照组用户有所扩大也是不对的，只有 d 是正确的。

&nbsp;
## 三、特征及训练样本
### 1. 特征介绍
模型的输入一般包括：用户画像特征、item 特征，上下文特征，交叉特征、位置特征和序列 item 特征，其中：

用户画像特征有：用户自身属性，如性别、年龄、职业、地域等；用户行为，如不同时间窗口的浏览时长、点击、搜索、发贴、收藏、点赞等行为；基于行为所产生的兴趣偏好，如车系、标签偏好等；基于行为的衍生统计指标，如用户 ctr、活跃度等。

Item 特征有：item 自身属性，如标题、正文字数、图片个数等；基于 item 挖掘的特征，如内容分类、关键词、情感、内容专业度、内容丰富度、作者影响力等；item 被用户赋予的行为，如 uv、pv、ctr、收藏、点赞、回复等。

交叉特征有：item 标签与用户标签的匹配度。
### 2. 特征处理
直接使用原始特征不易于模型拟合，所以传入模型后还需要进一步处理，具体包括：异常值处理、归一化和等频分桶。

异常值处理：

训练样本中的特征一般都存在异常值，对于离散型特征，可以将其单独分配到 one-hot 的一个位置，不会存在全为 0 的情况，但对于连续型特征，通常会对其赋默认值，如果为 0 则该特征不会参与到结果计算，如果为平均值则可能不符合各个特征的物理含义。为了得到合理的默认值，排序模型通过在特征处理阶段，对每个连续型特征引入不为 0 的 weight 和 bias，默认值的计算方式为：weight x featurevalue + bias，weight 和 bias 通过模型训练学到，当出现异常值时，特征值默认等于 bias。通过离线实验，测试集的 loss 有明显下降，上线后的 CTR 也优于默认取 0 值或取平均值。

归一化：

连续型特征的值分布一般不统一，例如曝光量和 CTR，曝光量取值都大于 1，且最大值可能会是几百万，而 CTR 的取值区间为 0 到 1，如果直接输入到排序模型，分布不均的统计特征会导致训练波动，不但影响收敛速度，而且最终可能会无法拟合。常规的归一化方法包括：min-max、log 和 standard 等，通过离线实验观察测试集的 loss，其中 min-max 的效果最好。

等频分桶：

对于连续型特征，当线上的特征值出现异常变化的时候，可能会存在泛化性不好或者鲁棒性不足的问题。为此引入了等频分桶，即按样本特征的分布频率，为每个特征规定好多个取值分界线，根据原始特征值分到不同的桶中，再根据桶的编号进行 one-hot 处理。深度模型的 NN 部分使用连续特征时因为长尾分布对最大值做了限制，后来实验 NN 部分使用离散特征效果更好，也使用了离散特征。
### 3. 特征表达
我们的排序模型不仅引入了大规模的稀疏特征，而且实现了多种形式的向量表达。

如基于 item 内容分类的 Bert embedding，基于 item 图像和视频的 embedding，基于行为的 Graph embedding、LSTM embedding 等。

### 4. 特征生产
用户和资源的特征做到了离线加实时，离线特征存储了用户和资源最近三个月的行为，实时特征做到了秒级别的更新。特征生产系统架构如下：


&nbsp;
## 四、未来计划的优化方向
模型目标：后续的优化目标不仅仅限于 CTR，而是综合点击、互动、时长等多个目标同时优化，这是未来目标优化的趋势。多目标模型的实现既可以每个目标独立建模优化然后进行融合，也可以通过共享参数的多目标网络实现。

模型表达能力：也就是网络结构的升级，如使用 Transformer 进行更好的特征抽取，自动化特征工程，AutoML 自动设计更好的网络模型，和推荐场景很吻合的强化学习等。

特征扩充及信息融合：主要有用户长短期兴趣更精准的 Embedding 表达，文本、图片、视频、互动行为等**多模态信息的融合表达等**。

&nbsp; 
## reference
[汽车之家推荐系统排序算法迭代之路](https://www.infoq.cn/article/87gOLIaqWZW4moL0G9Ke)
