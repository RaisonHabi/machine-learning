## 1、回归（Regression）算法指标
```
Mean Absolute Error 平均绝对误差
Mean Squared Error 均方误差
Root Mean Squared Error：均方根误差
Coefficient of determination 决定系数
```
怎样来衡量回归模型的好坏呢？ 我们第一眼自然而然会想到采用残差（实际值与预测值差值）的均值来衡量，即：  
。。。  
问题 1：用残差的均值合理吗？  
当实际值分布在拟合曲线两侧时，对于不同样本而言** 有正有负，相互抵消，因此我们想到采用预测值和真实值之间的距离来衡量**。


### 1.1 平均绝对误差 MAE
平均绝对误差MAE（Mean Absolute Error）又被称为 L1范数损失。

问题 2：MAE有哪些不足？

MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致函数不光滑，在某些点上不能求导，可以考虑将绝对值改为残差的平方，这就是均方误差。

### 1.2 均方误差 MSE
均方误差MSE（Mean Squared Error）又被称为 L2范数损失 。

问题 3： 还有没有比MSE更合理一些的指标？

由于MSE与我们的目标变量的量纲不一致，为了保证量纲一致性，我们需要对MSE进行开方 。

### 1.3 均方根误差 RMSE
问题 4： RMSE有没有不足的地方？有没有规范化（无量纲化的指标）？

上面的几种衡量标准的取值大小与具体的应用场景有关系，很难定义统一的规则来衡量模型的好坏。比如说利用机器学习算法预测上海的房价RMSE在2000元，我们是可以接受的，但是当四五线城市的房价RMSE为2000元，我们还可以接受吗？下面介绍的决定系数就是一个无量纲化的指标。

### 1.4 决定系数 R^2 （公式详见链接）
变量之所以有价值，就是因为变量是变化的。什么意思呢？比如说一组因变量为[0, 0, 0, 0, 0]，显然该因变量的结果是一个常数0，我们也没有必要建模对该因变量进行预测。假如一组的因变量为[1, 3, 7, 10, 12]，该因变量是变化的，也就是有变异，因此需要通过建立回归模型进行预测。这里的变异可以理解为一组数据的方差不为0。

决定系数又称为R^2 score，反映因变量的全部变异能通过回归关系被自变量解释的比例。

**如果结果是0，就说明模型预测不能预测因变量。 如果结果是1。就说明是函数关系。 如果结果是0-1之间的数，就是我们模型的好坏程度**。  
**化简上面的公式 ,分子就变成了我们的均方误差MSE，下面分母就变成了方差:**

#### yi:实际值；y^i:预测值；y-:实际值均值（详见链接2）

<p>决定系数即 R 平方值，反应因变量的全部变异能通过回归关系被自变量解释的比例。如R平方为0.8，则表示回归关系可以解释因变量80%的变异。换句话说，如果我们能控制自变量不变，则因变量的变异程度会减少 80%。 在简单线性回归中，绝对系数可以是 <code>R^2 = r * r</code>。而更通用的是：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-254f5004fb3ceaf68a6366ec593c1a63_b.jpg" data-caption="" data-size="normal" data-rawwidth="200" data-rawheight="46" class="content_image" width="200"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;200&#39; height=&#39;46&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="200" data-rawheight="46" class="content_image lazy" width="200" data-actualsrc="https://pic4.zhimg.com/v2-254f5004fb3ceaf68a6366ec593c1a63_b.jpg"/></figure><p class="ztext-empty-paragraph"><br/></p><p>SST 其实是两部分组成的，一部分是模型可预测的，一部分是变异的SSError无法用模型解释的。它们之间的计算公式是:</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-dd32ad2965e1bdeeefa3431c96c89357_b.jpg" data-caption="" data-size="normal" data-rawwidth="155" data-rawheight="135" class="content_image" width="155"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;155&#39; height=&#39;135&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="155" data-rawheight="135" class="content_image lazy" width="155" data-actualsrc="https://pic4.zhimg.com/v2-dd32ad2965e1bdeeefa3431c96c89357_b.jpg"/></figure><p class="ztext-empty-paragraph"><br/></p>

```
from sklearn import linear_model

def polyfit(x, y):
    linear = linear_model.LinearRegression()
    linear.fit(x, y)
    y_hat = linear.predict(x)
    y_mean = np.mean(y)
    SSR = 0
    SST = 0
    for i in range(len(y)):
        SSR += (y_hat[i] - y_mean) ** 2
        SST += (y[i] - y_mean) ** 2
    return SSR / SST
```

问题 5： 以上评估指标有没有缺陷，如果有，该怎样改进？

以上的评估指标是基于误差的均值对进行评估的，均值对异常点（outliers）较敏感，如果样本中有一些异常值出现，会对以上指标的值有较大影响，即均值是非鲁棒的。

### 1.5 解决评估指标鲁棒性问题
我们通常用一下两种方法解决评估指标的鲁棒性问题：
```
剔除异常值
设定一个相对误差 ，当该值超过一定的阈值时，则认为其是一个异常点，剔除这个异常点，将异常点剔除之 后。再计算平均误差来对模型进行评价。
使用误差的分位数来代替
如利用中位数来代替平均数。例如 MAPE:
```
MAPE是一个相对误差的中位数，当然也可以使用别的分位数。

&nbsp;
## 2、分类（Classification）算法指标
```
精度 Accuracy
混淆矩阵 Confusion Matrix
准确率（查准率） Precision
召回率（查全率）Recall
Fβ Score
AUC Area Under Curve
KS Kolmogorov-Smirnov
```
。。。

### AUC的物理意义 
AUC的物理意义正样本的预测结果大于负样本的预测结果的概率。  
所以AUC反应的是分类器对样本的排序能力。  
另外值得注意的是，AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价分类器性能的一个原因。

### AUC的计算
法1：AUC为ROC曲线下的面积，那我们直接计算面积可得。面积为一个个小的梯形面积（曲线）之和。计算的精度与阈值的精度有关 。

法2：根据AUC的物理意义，我们计算正样本预测结果大于负样本预测结果的概率。取n1* n0(n1为正样本数，n0为负样本数)个二元组，每个二元组比较正样本和负样本的预测结果，正样本预测结果高于负样本预测结果则为预测正确，预测正确的二元组占总二元组的比率就是最后得到的AUC。时间复杂度为O(N* M)。

法3：我们首先把所有样本按照score排序，依次用rank表示他们，如最大score的样本，rank=n (n=n0+n1，其中n0为负样本个数，n1为正样本个数)，其次为n-1。那么对于正样本中rank最大的样本，rank_max，有n1-1个其他正样本比他score小,那么就有(rank_max-1)-(n1-1)个负样本比他score小。其次为(rank_second-1)-(n1-2)。最后我们得到正样本大于负样本的概率为 :

#### 问题 15：为什么说 ROC 和AUC都能应用于非均衡的分类问题？

ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系 。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。

&nbsp;
## reference
[机器学习评估指标](https://zhuanlan.zhihu.com/p/36305931)   
[线性回归中的相关度和决定系数](https://zhuanlan.zhihu.com/p/32335608)
