## 理解复杂的机器学习模型
### 1.代理模型
代理模型是一种用于解释复杂模型的简单模型。  
最常见的建立方法是，**对原始输入和复杂模型给出的预测值建立简单线性回归或者决策树模型**。  
代理模型中所展示的系数、变量重要性、趋势以及交互作用，是复杂模型内部机制的一种体现。不过，几乎没有理论依据能够保证简单的代理模型能够以高精度表达出更复杂的模型。

#### 代理模型适用于何种尺度的可解释性？
一般而言，代理模型是全局性的。  
一个简单模型的全局可解释特性会用于解释一个更复杂模型的全局特性。不过，我们也无法排除代理模型对复杂模型条件分布的局部拟合能力，例如先聚类，再用自变量拟合预测值、拟合预测值的分位点、判断样本点属于哪一类等等，能够体现局部解释性。因为条件分布的一小段倾向于是线性的、单调的，或者至少有较好的模式，局部代理模型的预测精度往往比全局代理模型的表现更好。模型无关的局部可解释性描述（我们会在下一小节介绍）是一种规范化的局部代理模型建模方法。当然，我们可以把全局代理模型和局部代理模型一起使用，来同时获得全局和局部的解释性。

#### 代理模型能够帮助我们解释何种复杂程度的响应函数？
代理模型能够有助于解释任何复杂程度的机器学习模型，不过可能它们最有助于解释非线性、非单调的模型。

#### 代理模型如何帮我们提高对数据的理解？
代理模型可以针对复杂模型的内部机制向我们提供一些洞见，因此能提高我们对数据的理解。

#### 代理模型如何让模型更可信赖？
当代理模型的系数、变量重要性、趋势效应和交叉效应都符合人类的领域知识，被建模的数据模式符合合理预期时，模型的可信度会得以提升。当数据中存在轻微的或者人为的扰动时，或者数据来自于我们感兴趣领域的数据模拟，又或者数据随着时间改变时，如果结合敏感性分析进行检验发现，对于模型的解释是稳定的，并且贴合人类领域经验，符合合理预期，那么模型的可信度会得以提升。

&nbsp;
### 2.模型无关的局部可解释性描述（Local Interpretable Model-agnostic Explanation, LIME）
### 3.最大激发分析
### 4.敏感性分析
### 5.变量重要性的度量
#### 变量重要性的全局度量
#### 去除某一自变量的分析法（Leave-One-Covariate-Out, LOCO）

&nbsp;
## reference
[解释机器学习模型的一些方法（三）——理解复杂的机器学习模型](https://www.cnblogs.com/wmx24/p/9356939.html)   
[解释机器学习模型的一些方法（二）——在受监管的行业使用机器学习](https://www.cnblogs.com/wmx24/p/9356937.html)   
[解释机器学习模型的一些方法（一）——数据可视化](https://www.cnblogs.com/wmx24/p/9356930.html)   
[Facebook开源模型可解释库Captum，这次改模型有依据了](http://blog.itpub.net/69946223/viewspace-2660009/)
