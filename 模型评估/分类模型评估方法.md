## 背景：  
在模型建立之后，必须对模型的效果进行评估，因为数据挖掘是一个探索的过程，评估-优化是一个永恒的过程。

### scikit的classifier.predict()默认使用0.5?  
这是数学观点上唯一明智的门槛

&nbsp;
## 样本定义
positive（黑样本、正样本，label=1）  
negative（白样本、负样本，label=0）

&nbsp;
## 混淆矩阵： 
TP（实际为正预测为正），FP（实际为负但预测为正），TN（实际为负预测为负），FN（实际为正但预测为负）  
**查全率（召回率，recall）：**  
查全率＝ TP / (TP+FN)  
**查准率（精准率，Precision）：**  
查准率＝ TP / (TP+FP)  
**准确率：**  
**(ACC)** Accuracy=(TP+TN) / (TP+FP+TN+FN)  
**阴性预测值：**  
可以理解为负样本的查准率，计算公式：
NPV=TN / (TN+FN)  

ppv的全称是Positive Predicted Value，是和Precision（精度）完全一回事。

&nbsp;
## Gini和AUC的关系
在做信用评分卡研究时，除了用KS/AUC指标，还经常见到基尼系数(gini coefficient)。   
gini系数通常被用来判断收入分配公平程度。

根据《信用风险评分卡研究》这本书中所说公式Gini=2AUC-1“只有在将ROC曲线解释为洛伦兹曲线时才成立”，而且“二者并不相同”。

(详见链接图解)

ROC空间是一个以伪阳性率(FPR, false positive rate)为X轴，真阳性率(TPR, true positive rate)为Y轴的二维坐标系所代表平面。
```
TPR: 真阳性率，所有阳性样本中(TP+FN)，被分类器正确判断为阳的比例。
TPR = TP / (TP + FN) = TP / 所有真实值为阳性的样本个数
FPR: 伪阳性率，所有阴性样本中(FP+TN)，被分类器错误判断为阳的比例。
FPR = FP / (FP + TN) = FP / 所有真实值为阴性的样本个数
```
洛伦兹曲线的纵轴是违约数占违约总量百分比的累计值，也就是TPR，**而洛伦兹的横轴（被拒绝申请的百分比）是(FP+TP)/(TN+FP+FN+TP)，当坏样本很少时，FN和TP的值很小，因而洛伦兹曲线和ROC曲线横纵轴取值基本一致，曲线基本重合。但当坏样本较多时，二者不重合，且差距较大**。

**最后的结论是：当样本中坏样本极少时可用gini=2AUC-1近似计算，当坏样本较多，或者好坏样本接近1:1时，那就得对gini单独计算比较准确**。

### 关于Gini值的计算：
#### (1) 用公式gini=2AUC-1
```
from sklearn import metrics
auc_roc_score = metrics.roc_auc_score(target_label, predict_probabilty)
gini_by_roc_score = 2 * auc_roc_score - 1
```
#### (2) Gini的python直接计算可用下面文章中的代码：
```
def gini(actual, pred):
    assert (len(actual) == len(pred))
    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)
    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]
    totalLosses = all[:, 0].sum()
    giniSum = all[:, 0].cumsum().sum() / totalLosses

    giniSum -= (len(actual) + 1) / 2.
    return giniSum / len(actual)


def gini_normalized(actual, pred):
    return gini(actual, pred) / gini(actual, actual)


gini_predictions = gini(actual, predictions)
ngini= gini_normalized(actual, predictions)
```

[Gini和AUC的关系（Gini=2AUC-1真的成立吗？）](https://blog.csdn.net/dongweionly/article/details/83573878)

&nbsp;
## P-R曲线/PRC
**预测结果从大到小排序作为阈值**，precision为y轴，recall为x轴，绘制曲线  
*查准率和查全率通常是一对矛盾的度量，通常一个高，另外一个就低。两个指标都很重要，如何综合考虑这两个指标呢？*  
主要有两种办法:  
1."平衡点“(Break-Even Point, BEP):查准率=查全率的点;  
2. F1度量---查准率和查全率的加权调和平均数.  
[深度探讨机器学习中的ROC和PR曲线](https://blog.csdn.net/taoyanqi8932/article/details/54409314)

&nbsp;
## PR曲线与ROC的异同
同：  
都是刻画阈值的选择对分类度量指标的影响；   
异：  
pr曲线只关注正例的分类情况，roc则关注全局排序；  
当正负样本的比例发生很大变化时，roc变化不会特别明显，pr则非常敏感

&nbsp;
## ROC、AUC:
ROC曲线描绘的是不同的**阈值**时，并以FPR和TPR为横纵坐标轴，描述***随着截断点的变小，TPR随着FPR的变化。***    
纵轴：**TPR(true postive rate)=正例分对的概率 = TP/(TP+FN)，其实就是查全率（召回率）**         
***横轴：FPR=负例分错的概率 = FP/(FP+TN)***    
判断标准：  
1.一个ROC曲线完全”包住“另一个ROC曲线--->第一个学习器效果更好  
2.两个ROC曲线相交--->利用ROC曲线下的面积（AUC，area under ROC curve，是一个数值)进行比较  
***auc的意义：***  
**AUC表示，任取一对正负例，分类器给出正例得分大于负例得分的概率**  
auc意义的由来(3种计算方法)-->[二、AUC计算 ](https://blog.csdn.net/u013385925/article/details/80385873)   
[理解AUC](https://www.cnblogs.com/van19/p/5494908.html)  
***ROC曲线上的4个关键点：***  
> (0,0)：TP=0，FP=0，可以发现该分类器预测所有的样本都为负样本(Negative) **(阈值取预测结果的最大值)**     
(1,1)：TN=0，FN=0，可以发现该分类器预测所有的样本都为正样本(Positive)**(阈值取预测结果的最小值)**      
(0,1)：FP=0，FN=0，它将所有的样本都正确分类  
(1,0)：TP=0，TN=0，它将所有的样本都错误分类

&nbsp;
## KS: 
KS曲线和ROC曲线都用到了TPR，FPR。***KS曲线是把TPR和FPR都作为纵坐标，而样本数作为横坐标。***    
*好坏样本累计差异越大，KS指标越大，那么模型的风险**区分能力**越强。*   
KS的计算步骤如下：   
1.计算每个评分区间的好坏账户数。   
2.计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。   
3.计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。

&nbsp;
## GINI系数、洛伦兹曲线（Lorenz curve）: 
In economics, the Lorenz curve is a graphical representation of the distribution of income or of wealth. It was developed by Max O. Lorenz in 1905 for representing inequality of the wealth distribution.

The curve is a graph showing the proportion of overall income or wealth assumed by the bottom x% of the people, although this is not rigorously true for a finite population (see below). It is often used to represent income distribution, where it shows for the bottom x% of households, what percentage (y%) of the total income they have. The percentage of households is plotted on the x-axis, the percentage of income on the y-axis. It can also be used to show distribution of assets. In such use, many economists consider it to be a measure of social inequality.

<p>20世纪初意大利经济学家基尼，于1922年提出的定量测定收入分配差异程度的指标。它是根据洛伦茨曲线找出了判断分配平等程度的指标（如下图）。</p>
<p><span class="image"><img src="http://wiki.mbalib.com/w/images/f/fa/%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0.jpg" alt="Image:基尼系数.jpg" longdesc="/wiki/Image:%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0.jpg" /></span></p>
<p>　　设实际收入分配曲线和收入分配绝对平等曲线之间的面积为A，实际收入分配曲线右下方的面积为B。并以A除以A+B的商表示不平等程度。这个数值被称为基尼系数或称洛伦茨系数。如果A为零，基尼系数为零，表示收入分配完全平等；如果B为零则系数为1，收入分配绝对不平等。该系数可在零和1之间取任何值。收入分配越是趋向平等，洛伦茨曲线的弧度越小，基尼系数也越小，反之，收入分配越是趋向不平等，洛伦茨曲线的弧度越大，那么基尼系数也越大。如果个人所得税能使收入均等化，那么，基尼系数即会变小。</p>
<p>　　基尼系数的计算公式为：</p>
<p>　　<img class="tex" src="http://wiki.mbalib.com/w/images/math/9/7/c/97c0b9b8b5d66238e5bda8ee187b2f32.png" alt="G=\sum_{i=1}^n {X_i}{Y_i}+2\sum_{i=1}^n {X_i}(1V_i}) -1" /></p>
<p>　　其中，X代表各组的人口比重，Y代表各组的收入比重，V代表各组累计的收入比重，i=1，2，3，&hellip;，n，n代表分组的组数。</p>

&nbsp;

<p><strong>劳伦茨曲线</strong>是1905年由经济学家马克斯&middot;劳伦茨所提出的表示收入分配的曲线，意大利经济学家科拉多&middot;基尼在此基础上定义了基尼系数。</p>
<p>在经济学里，劳伦兹曲线是在过往财富分配数据上建立的累积分布函数所对应的曲线，它通过变量y%的值来反映各项分配的比例。它经常被用来描述收入的分配情况，即以x%代表一部分（收入相似）家庭占整个社会家庭的比例，以y%代表该部分家庭的收入占整个社会收入的比例。该曲线也可用来描述社会资本的分配情况。在这些应用当中，经济学家经常把它用来衡量社会（主要指社会收入）是否公平。<span class="mw-redirect">概率密度函数</span>（<em>f</em>(<em>x</em>)）或累积分布函数（<em>F</em>(<em>x</em>)）：</p>
<dl><dd><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"> L ( F ) = &int; &minus; &infin; x ( F ) x f ( x ) d x &int; &minus; &infin; &infin; x f ( x ) d x = &int; 0 F x ( F &prime; ) d F &prime; &int; 0 1 x ( F &prime; ) d F &prime; {\displaystyle L(F)={\frac {\int _{-\infty }^{x(F)}xf(x)\,dx}{\int _{-\infty }^{\infty }xf(x)\,dx}}={\frac {\int _{0}^{F}x(F')\,dF'}{\int _{0}^{1}x(F')\,dF'}}} <img class="mwe-math-fallback-image-inline" style="vertical-align: -3.505ex; width: 40.643ex; height: 8.343ex;" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/43b1d253a67dc88413a9393998cdebf64190d04c" alt="L(F)={\frac  {\int _{{-\infty }}^{{x(F)}}xf(x)\,dx}{\int _{{-\infty }}^{\infty }xf(x)\,dx}}={\frac  {\int _{0}^{F}x(F')\,dF'}{\int _{0}^{1}x(F')\,dF'}}" /></span></dd></dl>
<p>这曲线在发展经济学上，除了用于常见的基尼系数表示收入分布，还有土地分布，教育度的程度的分布等。</p>
<p>____________________________________________________________</p>
<p><b>画一个矩形，矩形的高衡量社会财富的百分比，将之分为五等份，每一等分为20的社会总财富。在矩形的长上，将100的家庭从最贫者到最富者自左向右排列，也分为5等分，第一个等份代表收入最低的20的家庭。在这个矩形中，将每一百分的家庭所有拥有的财富的百分比<strong>累计起来</strong>，并将相应的点画在图中，便得到了一条曲线就是洛伦兹曲线。</b></p>
<p>　　<span class="image"><img src="http://wiki.mbalib.com/w/images/f/f2/%E6%B4%9B%E4%BC%A6%E5%85%B9%E6%9B%B2%E7%BA%BF.jpg" alt="洛伦兹曲线" longdesc="/wiki/Image:%E6%B4%9B%E4%BC%A6%E5%85%B9%E6%9B%B2%E7%BA%BF.jpg" width="290" height="265" /></span></p>
<p>　　 显而易见，洛伦兹曲线的弯曲程度具有重要意义。一般来说，它反映了收入分配的不平等程度。弯曲程度越大，收入分配程度越不平等；反之亦然。特别是，如果所有收入都集中在某一个人手中，而其余人口均一无所有，收入分配达到完全不平等，洛伦兹曲线成为折线OHL；另一方面，如果任一人口百分比等于其收入百分比，从而人口累计百分比等于收入累计百分比，则收入分配就是完全平等的，洛伦兹曲线成为通过原点的45度线OL。<span id="transmark" style="display: none; width: 0px; height: 0px;"></span></p>

&nbsp;


### 洛伦兹曲线绘制
1.从差到优给用户排序（评分由低到高）；  
2.把用户等分（例如十等分）；  
3.计算每份中坏用户个数（黑样本）；  
4.**累计**每份坏用户数，描点作图  

&nbsp;

&nbsp;
## Lift: 
Lift图衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。  
Lift=(TP/(TP+FP))/(P/(P+N))  

#### lift指标已经用来评价一些排序类的模型，在计算广告领域用的比较多。
比如在一家商场门口路过的1000个行人当中，我们只能发放100张优惠券。
第一次我们进行随机发放100张，他们进入商城消费，商城盈利为100元。

第二次我们利用模型判断给哪些人发放，模型挑选出了100位消费能力、消费意愿强的行人，他们进入商城消费，最终商城盈利500元。

我们将两者对比，实际上就是模型和随机猜测(baseline模型)的对比，两者的比值就是称为lift，这里lift=500/100=5。

上面的例子中，我们发放的比例是10%，如果发放比例是100%的时候，模型的lift就是1，因为和随机猜测一样，都是每个人都发。以优惠券发放的比例为x轴，lift为y轴，我们就可以得到lift曲线图。  
(图详见链接)

#### 对于分类模型也是可以用lift曲线的。
比如说我们要进行信用卡欺诈检测（有监督二分类），假设信用卡欺诈占总交易的1%。所以如果我们从20%的样本中随机猜测，正确率也只有1%。如果我们有一个模型进行分类，我们把认为最有可能是欺诈的20%挑出来，验证得到正确率有15%，那么此时lift就是15。

[机器学习中lift的概念是什么？怎么用来评价模型？](http://sofasofa.io/forum_main_post.php?postid=1006038)

&nbsp;
## Gain: 
Gain图是描述整体精准度的指标。Gain=TP/(TP+FP)  

&nbsp;
## PSI:  
群体稳定性指标PSI(Population Stability Index)是衡量模型的预测值与实际值偏差大小的指标。  
PSI = sum（（实际占比-预期占比）* ln（实际占比/预期占比））  

&nbsp;
## reference
[分类模型的评价指标--混淆矩阵，ROC，AUC，KS，Lift，Gain](https://blog.csdn.net/shy19890510/article/details/79501582)  
[神秘的KS值和GINI系数](https://blog.csdn.net/u013421629/article/details/78217498)  
[基尼系数（Gini coefficient）,洛伦茨系数](https://www.cnblogs.com/sddai/p/6274859.html)  
