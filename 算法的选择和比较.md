## 机器（统计）学习的两种假设检验
**1.针对特定数据集上的特定模型（如逻辑回归），分析不同变量的显著性**  
**2.在多个数据集上对比多个分类器的性能，分析不同模型表现的差异**

### 1.先讨论第一类检验（特定数据集上变量的显著性）
在社科类文章中的数据分析（如回归）是工具，目的是从数据中归纳结论。而在计算机领域，目的是设计新的模型，而不是分析数据，一般不会专门对实验数据下结论。换句话说：<b>社科类研究中数据分析是工具，而机器学习的目的往往是模型而不是数据本身</b>。</p><p>因为这个原因，我们发现在社科类文章中往往是“对特定数据集上的一个回归模型的变量做显著性分析，来证明某个变量是否对模型有意义”。比如一个数据集有性别、年龄、收入三个变量，分析这几个变量对于患糖尿病的影响。在这种情况下，做统计检验无可厚非。</p><p><b>当然，这样做也有风险和偶然性。</b>比如我常说的一个例子：Freedman在1989年做过的模拟实验 [1]中发现，即使数据全是由噪音构成，在适当的处理后，也能发现数据中显著的相关性：6个特征显著且对回归所做的F-test的p值远小于0.05，即回归存在统计学意义。更多例子可以看：<a href="https://www.zhihu.com/question/66895407/answer/381880059" class="internal">微调：有哪些相关性不等于因果性的例子?</a></p><p><b>除此之外，我们也认为广义线性模型的数据挖掘能力有限，对于复杂的非线性数据可能无法很好的拟合</b>。所以社科类文章中的很多结论也不完全正确，但受限于数据，往往这就是当下的最优解。正因为如此，也有不少研究者在呼吁弱化p值的重要性。</p><p><b>而在机器学习中，一个变量是否重要，往往是通过“特征选择”和“特征重要性排序”来体现的</b>。比如大部分决策树模型和集成树模型都可以提供一个变量重要性排序，可以等同视为统计检验。从实际效果上看，往往更好。</p><p>但为什么大部分社科类研究必须要用广义线性回归模型呢？<b>主要是为了可解释性，来说明不同变量对最终结果的“贡献”，因此另一个附加价值就是统计检验</b>。而机器学习因为其黑箱性导致了不大适合用于数据分析，也就不存在统计检验。<b>值得注意的，虽然没有统计检验，但受益于机器学习中各种复杂模型的有效性，预测结果往往更准确，而且也可以得到很多有价值的分析结果</b>。但用于学术研究的话，往往人们无法信任纯粹的对比和变量重要性排序，因此社科类中很多研究还是基于各种线性回归。

### 2.再讨论第二类情况（对比多个模型在多个数据集上的表现）
其实这是机器学习，尤其是传统机器学习方向的一个趋势，越来越多的论文要求提供统计检验。我最近的一篇论文的审稿意见就有这么一条：“必须做统计检验”。</p><p>当然，这个要求有时并不合理，在特定领域也没有必要，原因如下：</p><ul><li>需要一定数量的数据集（样本量），一般来说大于10个，甚至15个数据集比较好。但这样显然是不现实的，很多领域（如机器视觉）的数据集非常大。如果是深度学习在多个大数据集上运行的开销过大，大部分情况并不现实。</li><li>当数据集已经非常大且具有代表性时，没有必要做统计检验。举个简单的例子，如果有世界上百分之99人的图片，并用其预测剩下百分之1的人性别。那么在99%数据上表现足够好的模型应该就是最好的，不必多此一举。说到底，这个可能是统计学和机器学习的差异，前者更严谨后者更有效，难分优劣。</li><li>不可否认，很多人其实是做过统计检验的，因为不显著于是又删掉了。换句话说，回避统计检验一定程度上也造成了灌水现象...</li></ul><p>但话说回来，在传统机器学习领域，尤其是大量使用UCI上数据集的研究（如很多无监督学习），其实是可以做统计检验的，因为数据集都不大且数量众多。而在机器学习模型上做统计检验的重要性在2006年就有一篇JMLR论文讨论过[3]，结合我的一些经验可以简单归纳为：</p><blockquote>首先结论如下，在对比<b>两个算法</b>在<b>多个数据集</b>上的表现时：<br/>- 如果样本配对（paired）且符合正态分布，优先使用配对t检测（paired t test）。<br/>- 如果样本不符合正态分布，但符合配对，使用Wilcoxon Signed Ranks test。<br/>- 如果样本既不符合正态分布，也不符合配对，甚至样本量都不一样大，可以尝试Mann Whitney U test。值得注意的是，MW是用来处理独立测量（independent measures）数据，要分情况讨论，后文会深入分析。<br/><br/>在对比<b>多个算法</b>在<b>多个数据集</b>上的表现时：<br/>- 如果样本符合ANOVA（repeated measure）的假设（如正态、等方差），优先使用ANOVA。<br/>- 如果样本不符合ANOVA的假设，使用Friedman test配合Nemenyi test做post-hoc。<br/>- 如果样本量不一样，或因为特定原因不能使用Friedman-Nemenyi，可以尝试Kruskal Wallis配合Dunn&#39;s test。值得注意的是，这种方法是用来处理独立测量数据，要分情况讨论。</blockquote><p>更详细的如何用统计检验对比机器学习模型，请参考：<a href="https://www.zhihu.com/question/27306416/answer/372241948" class="internal">微调：常用的机器学习算法比较？</a></p><hr/><p>[1] Freedman, L.S. and Pee, D., 1989. Return to a note on screening regression equations. <i>The American Statistician</i>, <i>43</i>(4), pp.279-282.</p><p>[2] <a href="https://link.zhihu.com/?target=http%3A//www.tylervigen.com/spurious-correlations" class=" wrap external" target="_blank" rel="nofollow noreferrer">15 Insane Things That Correlate With Each Other</a></p><p>[3] Demšar, J., 2006. Statistical comparisons of classifiers over multiple data sets. <i>Journal of Machine learning research</i>, <i>7</i>(Jan), pp.1-30.</p></span></div><div><div class="ContentItem-time"><a target="_blank" href="/question/55420602/answer/394577531">

&nbsp;
## 常用的机器学习算法比较

## reference
[Choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/)  
[常用的机器学习算法比较？](https://www.zhihu.com/question/27306416/answer/372241948)  
[常用的机器学习算法比较？ - 于菲的回答 - 知乎](https://www.zhihu.com/question/27306416/answer/36701217)  
[Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf)   
[为什么做机器学习的很少使用假设检验？ - 微调的回答 - 知乎](https://www.zhihu.com/question/55420602/answer/394577531)  
[]()  
