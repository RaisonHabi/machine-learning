<h2><b>先放结论</b></h2><p><b>PyTorch更有利于研究人员、爱好者、小规模项目等快速搞出原型。而TensorFlow更适合大规模部署，特别是需要跨平台和嵌入式部署时。</b></p><p>然后咱们一项一项分着说。</p><h2><b>上手时间</b></h2><p>赢家：PyTorch</p><p>PyTorch本质上是Numpy的替代者，而且支持GPU、带有高级功能，可以用来搭建和训练深度神经网络。如果你熟悉Numpy、Python以及常见的深度学习概念（卷积层、循环层、SGD等），会非常容易上手PyTorch。</p><p>而TensorFlow可以看成是一个嵌入Python的编程语言。你写的TensorFlow代码会被Python编译成一张图，然后由TensorFlow执行引擎运行。我见过好多新手，因为这个增加的间接层而困扰。也正是因为同样的原因，TensorFlow有一些额外的概念需要学习，例如会话、图、变量作用域（variable scoping）、占位符等。</p><p>另外还需要更多的样板代码才能让一个基本的模型运行。所以TensorFlow的上手时间，肯定要比PyTorch长。</p><h2><b>图创建和调试</b></h2><p>赢家：PyTorch</p><p>创建和运行计算图可能是两个框架最不同的地方。在PyTorch中，图结构是动态的，这意味着图在运行时构建。而在TensorFlow中，图结构是静态的，这意味着图先被“编译”然后再运行。</p><p>举一个简单的例子，在PyTorch中你可以用标准的Python语法编写一个for循环结构</p><div class="highlight"><pre><code class="language-text">for _ in range(T):
    h = torch.matmul(W, h) + b</code></pre></div><p>此处T可以在每次执行代码时改变。而TensorFlow中，这需要使用“控制流操作”来构建图，例如tf.while_loop。TensorFlow确实提供了dynamic_rnn用于常见结构，但是创建自定义动态计算真的更加困难。</p><p>PyTorch中简单的图结构更容易理解，更重要的是，还更容易调试。调试PyTorch代码就像调试Python代码一样。你可以使用pdb并在任何地方设置断点。调试TensorFlow代码可不容易。要么得从会话请求要检查的变量，要么学会使用TensorFlow的调试器（tfdbg）。</p><p class="ztext-empty-paragraph"><br/></p><figure><noscript><img src="https://pic2.zhimg.com/v2-5703b6e4d0240b595d071edd55cba8d9_b.gif" data-rawwidth="252" data-rawheight="448" data-thumbnail="https://pic2.zhimg.com/v2-5703b6e4d0240b595d071edd55cba8d9_b.jpg" class="content_image" width="252"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;252&#39; height=&#39;448&#39;&gt;&lt;/svg&gt;" data-rawwidth="252" data-rawheight="448" data-thumbnail="https://pic2.zhimg.com/v2-5703b6e4d0240b595d071edd55cba8d9_b.jpg" class="content_image lazy" width="252" data-actualsrc="https://pic2.zhimg.com/v2-5703b6e4d0240b595d071edd55cba8d9_b.gif"/></figure><p class="ztext-empty-paragraph"><br/></p><h2><b>全面性</b></h2><p>赢家：TensorFlow</p><p>随着PyTorch逐渐成熟，我预计这部分的差距会趋近于零。但目前，TensorFlow还是有一些PyTorch不支持的功能。它们是：</p><ul><li>沿维翻转张量（np.flip, np.flipud, np.fliplr）</li><li>检查无穷与非数值张量（np.is_nan, np.is_inf）</li><li>快速傅里叶变换（np.fft）</li></ul><p>这些TensorFlow都支持。另外，TensorFlow的contrib软件包中，有更多PyTorch没有的高级功能和模型。</p><h2><b>序列化</b></h2><p>赢家：TensorFlow</p><p>两种框架下保存和加载模型都很简单。PyTorch有一个特别简单的API，可以保存模型的所有权重或pickle整个类。TensorFlow的Saver对象也很易用，而且为检查提供了更多的选项。</p><p>TensorFlow序列化的主要优点是可以将整个图保存为protocol buffer。包括参数和操作。然而图还能被加载进其他支持的语言（C++、Java）。这对于部署堆栈至关重要。理论上，当你想改动模型源代码但仍希望运行旧模型时非常有用。</p><h2><b>部署</b></h2><p>赢家：TensorFlow</p><p>对于小规模的服务器端部署（例如一个Flask web server），两个框架都很简单。</p><p>对于移动端和嵌入式部署，TensorFlow更好。不只是比PyTorch好，比大多数深度学习框架都要要。使用TensorFlow，部署在Android或iOS平台时只需要很小的工作量，至少不必用Java或者C++重写模型的推断部分。</p><p>对于高性能服务器端的部署，还有TensorFlow Serving能用。除了性能之外，TensorFlow Serving一个显著的优点是可以轻松的热插拔模型，而不会使服务失效。</p><h2><b>文档</b></h2><p>赢家：平手</p><p>对于两个框架，我都在文档中找到所需的一切。Python API被很好的记录，以及有足够的案例和教程来学习框架。</p><p>一个特例是，PyTorch的C库大多数没有文档。不过，这只有在你编写一个定制化的C扩展时才有影响。</p><h2><b>数据加载</b></h2><p>赢家：PyTorch</p><p>PyTorch中用于加载数据的API设计的很棒。接口由一个数据集、一个取样器和一个数据加载器构成。数据加载器根据取样器的计划，基于数据集产生一个迭代器。并行化数据加载简单的就像把num_workers参数传递给数据加载器一样简单。</p><p>我在TensorFlow中没有发现特别有用的数据加载工具。很多时候，并不总能直接把准备并行运行的预处理代码加入TensorFlow图。以及API本身冗长难学。</p><h2><b>设备管理</b></h2><p>赢家：TensorFlow</p><p>TensorFlow的设备管理非常好用。通常你不需要进行调整，因为默认的设置就很好。例如，TensorFlow会假设你想运行在GPU上（如果有的话）。而在PyTorch中，即使启用了CUDA，你也需要明确把一切移入设备。</p><p>TensorFlow设备管理唯一的缺点是，默认情况下，它会占用所有的GPU显存。简单的解决办法是指定CUDA_VISIBLE_DEVICES。有时候大家会忘了这一点，所以GPU在空闲的时候，也会显得很忙。</p><p>在PyTorch中，我发现代码需要更频繁的检查CUDA是否可用，以及更明确的设备管理。在编写能够同时在CPU和GPU上运行的代码时尤其如此。以及得把GPU上的PyTorch变量转换为Numpy数组，这就显得有点冗长。</p><div class="highlight"><pre><code class="language-text">numpy_var = variable.cpu().data.numpy()</code></pre></div><h2><b>自定义扩展</b></h2><p>赢家：PyTorch</p><p>两个框架都可以构建和绑定用C、C++、CUDA编写的自定义扩展。TensorFlow仍然需要更多的样板代码，尽管这对于支持多类型和设备可能更好。在PyTorch中，你只需为每个CPU和GPU编写一个接口和相应的实现。两个框架中编译扩展也是直接记性，并不需要在pip安装的内容之外下载任何头文件或者源代码。</p><h2><b>关于TensorBoard</b></h2><p class="ztext-empty-paragraph"><br/></p><figure><noscript><img src="https://pic4.zhimg.com/v2-0d5e9e45eb39e5e73791706c92a347ea_b.png" data-rawwidth="1198" data-rawheight="683" class="origin_image zh-lightbox-thumb" width="1198" data-original="https://pic4.zhimg.com/v2-0d5e9e45eb39e5e73791706c92a347ea_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1198&#39; height=&#39;683&#39;&gt;&lt;/svg&gt;" data-rawwidth="1198" data-rawheight="683" class="origin_image zh-lightbox-thumb lazy" width="1198" data-original="https://pic4.zhimg.com/v2-0d5e9e45eb39e5e73791706c92a347ea_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0d5e9e45eb39e5e73791706c92a347ea_b.png"/></figure><p class="ztext-empty-paragraph"><br/></p><p>TensorBoard是TensorFlow自带的可视化工具，用来查看机器学习训练过程中数据的变化。通过训练脚本中的几个代码段，你可以查看任何模型的训练曲线和验证结果。TensorBoard作为web服务运行，特别便于对于无头结点上存储的结果进行可视化。</p><p>如果没有类似的功能，我可不想用PyTorch。不过还好，借助两个开源项目可以实现。第一个是tensorboard_logger，第二个是crayon。tensorboard_logger库用起来甚至比TensorBoard的“摘要”更容易，尽管想用这个首先得安装TensorBoard。</p><p>crayon可以完全替代TensorBoard，但是需要更多的设置（docker是先决条件）。</p><h2><b>关于Keras</b></h2><p>Keras是具有可配置后端的高级API。目前TensorFlow、Theano、CNTK都支持。也许不久的将来，PyTorch也会提供支持。作为tf.contrib的一部分，Keras也随TensorFlow一起分发。</p><p>虽然上面我没有讨论过Keras，但其API特别容易使用，这也是配合常见深度神经网络架构最快的方式。不过，使用API毕竟没有使用PyTorch或者核心TensorFlow那么灵活。</p><p>Keras是许多常用的深层神经网络架构中运行最快的方法之一。</p><h2><b>关于TensorFlow Fold</b></h2><p>今年2月，谷歌推出了TensorFlow Fold。这个库建立在TensorFlow智商，允许构建更多的动态图。这个库的主要优势是动态批处理。动态批处理可以自动对不同大小的输入进行批量计算（例如解析树上的循环网络）。</p><p>可编程性方面，语法不像PyTorch那么简单，当然在某些情况下，批处理带来的性能提升还是值得考虑。</p>

&nbsp;
## reference
[PyTorch还是TensorFlow？这有一份新手深度学习框架选择指南](https://zhuanlan.zhihu.com/p/28636490)
