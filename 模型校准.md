## 背景
基于风险预测模型的预后研究一直以来都是研究者关注的热点，各种各样的预测模型质量参差不齐，常常让人眼花缭乱，那么如何去评价一个模型的好坏，或者说当你构建出一个疾病风险预测模型后，它到底靠不靠谱，值不值得去推广和使用呢？这是一个我们需要去好好考量的问题。

&nbsp;

一个好的疾病风险预测模型，它不只是简单的因变量和自变量的数学组合，它背后的实际临床意义才是我们所要把握的重点，这就要求预测模型不仅要有很好的**区分度（Discrimination），同时还要具备良好的校准度（Calibration）**。

&nbsp;

Discrimination和Calibration是我们在评价预测模型时最常用到的一对指标，但是2015年Circ Cardiovasc Qual Outcomes杂志（影响因子：4.5）上发表的一项关注心血管疾病预测模型的系统综述发现，63%的研究报告了预测模型的Discrimination信息，但仅36%的研究报告了Calibration信息，使得预测模型的质量成为研究泛滥的重灾区。

本期内容我们就来向大家介绍一下这两个重要的指标，尤其是常常被人忽略的Calibration。

&nbsp;

## 区分度(Discrimination)
介绍Calibration之前，我们先简单介绍一下Discrimination。顾名思义，一个好的疾病风险预测模型，它能够把未来发病风险高、低不同的人群正确地区分开来，预测模型通过设置一定的风险界值，高于界值判断为发病，低于界值则判断为不发病，从而正确区分个体是否会发生结局事件，这就是预测模型的区分度(Discrimination)。

&nbsp;

**评价预测模型区分能力的指标，最常用的就是大家非常熟悉的ROC曲线下面积（AUC），也叫C统计量（C-statistics）**。AUC越大，说明预测模型的判别区分能力越好。一般AUC<0.6认为区分度较差，0.6-0.75认为模型有一定的区分能力，>0.75认为区分能力较好。

&nbsp;

## 校准度(Calibration)
预测模型的校准度(Calibration)，是***评价一个疾病风险模型预测未来某个个体发生结局事件概率准确性的重要指标，它反映了模型预测风险与实际发生风险的一致程度，所以也可以称作为一致性***。校准度好，提示预测模型的准确性高，校准度差，则模型有可能高估或低估疾病的发生风险。

&nbsp;

在实际的应用中，**通常用Hosmer-Lemeshow good of fit test（拟合优度检验）来评价预测模型的校准度**。Hosmer-Lemeshow检验的基本思路如下：  
> 1.首先根据预测模型来计算每个个体未来发生结局事件的预测概率；  
2.根据预测概率从小到大进行排序，并按照十分位等分成10组；  
3.分别计算各组的实际观测数和模型预测数，其中模型预测数，即每个人的预测概率*人数，再求总和（这里人数即为1，最后总和就相当于每个个体预测概率的直接加和）；   
> 4.根据每组实际观测数和模型预测数计算卡方值（自由度=8），再根据卡方分布得到对应的P值。  

&nbsp;

若所得的统计量卡方值越小，对应的P值越大，则提示预测模型的校准度越好。若检验结果显示有统计学显著性（P<0.05），则表明模型预测值和实际观测值之间存在一定的差异，模型校准度差。

&nbsp;

## 总结
Discrimination和Calibration是评价预测模型效能的两个重要指标，但比较容易混淆，最后再和大家总结一下：

1.&nbsp;Discrimination区分度，就是在模型的预测值中，看是否能够找到一个截点，使得把患者和非患者正确区分开来。如果区分的越开，且与实际情况越吻合，则提示模型的区分度越好。

2.&nbsp;Calibration校准度，就是评价模型预测值的大小和结局事件发生概率的大小是否一致。如果模型的预测值与结局实际发生概率越接近，则提示模型的校准度就越好。

3.&nbsp;风险预测模型的Discrimination和Calibration并不一定都是同方向的。

4.&nbsp;对于一个疾病预测模型，在利用Discrimination和Calibration进行评价时，我们首先需要考虑的是模型的区分能力Discrimination，如果模型的区分度较差，不能正确的将不同风险的人群区分开来，那么它就不是一个合格的预测模型，失去了临床的应用价值，再继续评价Calibration也没有太大的意义了。

&nbsp;

## reference
[Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good Probabilities With Supervised Learning,](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf)  
[你的预测模型靠谱吗？详解区分度和校准度的SPSS操作！](https://www.mediecogroup.com/method_topic_article_detail/230/?ty=methods)  
[专题全面了解诊断试验及ROC](https://www.mediecogroup.com/method_topic_detail/10/1/)  
[模型校准calibration](https://zhuanlan.zhihu.com/p/101766505)   
[概率校准 calibration_curve](https://zhuanlan.zhihu.com/p/90479183)  
[sklearn.calibration.calibration_curve](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html)  
[概率校准(Probability calibration)](https://www.studyai.cn/modules/calibration.html)  
[模型校准calibration ](https://www.zhihu.com/search?type=content&q=%E6%A8%A1%E5%9E%8B%E6%A0%A1%E5%87%86)
