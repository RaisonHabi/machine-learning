### word2vec训练词向量时间：  
用wiki的中文语料训练：用的是gensim，据说比C的版本快。服务器单机跑CPU核心数个线程，跑了35分钟。

tensorflow来训练word2vec比较麻烦，生成batch、定义神经网络的各种参数，都要自己做，但是对于理解算法原理有帮助：
```
1.读取文本数据，分词，清洗，生成符合输入格式的内容；
2.建立词汇表；
3.为skip-gram模型生成训练的batch；
4.定义和训练skip-gram模型；
5.词向量可视化。
```
### 文本分布式表示（二）：用tensorflow和word2vec训练词向量
预训练的词向量1.3G；新闻文本一两百M，训练出来七百多M。tf训练七八个小时左右
