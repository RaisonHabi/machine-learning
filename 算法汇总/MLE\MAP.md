**把先验假设去掉，或者假设先验满足均匀分布的话（无信息先验），此时贝叶斯方法等同于频率方法（最大后验概率估计等同于最大似然估计），即最大似然估计是一种特殊的最大后验概率估计**
## 一、MLE、MAP
最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法

### 0.概率和统计是一个东西吗？
概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。

概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。

统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。

一句话总结：**概率是已知模型和参数，推数据。统计是已知数据，推模型和参数**。

显然，本文解释的**MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法**。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。

### 1.贝叶斯公式(Bayes’ Theorem)
P(A|B)=P(B|A)P(A)/P(B)  【式1】  
贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。

把B展开，可以写成：  
P(A|B)=P(B|A)P(A)/P(B|A)P(A)+P(B|∼A)P(∼A) 【式2】（∼A表示”非A”）  
这个式子就很有意思了。

贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）

从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。 

从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。
### 2.似然函数
似然（likelihood）这个词其实和概率（probability）是差不多的意思，Colins字典这么解释：The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念（其实也很相近就是了）。

对于这个函数：P(x|θ)  
输入有两个：x表示某一个具体的数据；θ表示模型的参数。
```
如果θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。
如果x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。
```
### 3.最大似然估计（MLE）
假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为θ）各是多少？

这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！

于是我们拿这枚硬币抛了10次，得到的数据（x0）是：反正正正正反正正正反。**我们想求的正面概率θ是模型参数，而抛硬币模型我们可以假设是 二项分布**。    
那么，出现实验结果x0（即反正正正正反正正正反）的似然函数是多少呢？  
f(x0,θ)=(1−θ)×θ×θ×θ×θ×(1−θ)×θ×θ×θ×(1−θ)=θ7(1−θ)3=f(θ)
注意，**这是个只关于θ的函数。而最大似然估计，顾名思义，就是要最大化这个函数**。我们可以画出f(θ)的图像：(或对f(θ)求导)  
可以看出，在θ=0.7时，似然函数取得最大值（导数为0）。

当然实际中我们一般不会画图，而是通过更为简洁的数学手段来处理。  
首先我们取对数似然函数，这样更方便后续的数学运算： ln(f(X,θ))=ln(θ7(1−θ)3)=7ln(θ)+3ln(1−θ)   
对对数似然函数求导：ln′(f(X,θ))=7θ−31−θ  
令导数为0:7(1−θ)−3θ=0  
最终求得：θ=0.7

这样，我们已经完成了对θ的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。  

且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信θ=0.7。   
**这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计**。
### 4.最大后验概率估计
**最大似然估计是求参数θ, 使似然函数P(x0|θ)最大**。  
最大后验概率估计则是想求θ使P(x0|θ)P(θ)最大。  
**求得的θ不单单让似然函数大，θ自己出现的先验概率也得大**。 （这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法）

MAP其实是在最大化P(θ|x0)=P(x0|θ)P(θ)/P(x0)，不过因为x0是确定的（即投出的“反正正正正反正正正反”），P(x0)是一个已知值，所以去掉了分母P(x0)  
（假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则P(x0)=n/1000。总之，这是一个可以由数据集得到的值）。

**最大化P(θ|x0)的意义也很明确，x0已经出现了，要求θ取什么值使P(θ|x0)最大。顺带一提，P(θ|x0)即后验概率，这就是“最大后验概率估计”名字的由来**。
### 5.什么时候 MAP 估计与最大似然估计相等？
**当先验分布均匀之时，MAP 估计与 MLE 相等**。  
直观讲，它表征了最有可能值的任何先验知识的匮乏。在这一情况中，所有权重分配到似然函数，因此当我们把先验与似然相乘，由此得到的后验极其类似于似然。  
**因此，最大似然方法可被看作一种特殊的 MAP**。

**如果先验认为这个硬币是概率是均匀分布的，被称为无信息先验( non-informative prior )，通俗的说就是“让数据自己说话”，此时贝叶斯方法等同于频率方法**。

随着数据的增加，先验的作用越来越弱，数据的作用越来越强，参数的分布会向着最大似然估计靠拢。而且可以证明，最大后验估计的结果是先验和最大似然估计的凸组合。

&nbsp;
## 二、最大似然估计和EM算法的关系是什么？
Maximum likelihood estimation  
Expectation maximization algorithm

EM算法可以看成**是特殊情况下计算极大似然的一种算法**。

**现实的数据经常有一些比较奇怪的问题，比如缺失数据、含有隐变量等问题。当这些问题出现的时候，计算极大似然函数通常是比较困难的，而EM算法可以解决这个问题**。

EM算法已经有很多应用，比如最经典的Hidden Markov模型等。

如果我们关心的参数为θ，观察到的数据为y，隐藏变量为z，那么根据全概率公式：  
<img src="https://www.zhihu.com/equation?tex=P%28y%7C%5Ctheta%29%3D%5Cint+P%28y%7Cz%2C%5Ctheta%29f%28z%7C%5Ctheta%29dz" alt="P(y|\theta)=\int P(y|z,\theta)f(z|\theta)dz" eeimg="1"/>  
理论上，只要最大化这个密度函数的对数，就可以得到极大似然估计。  
**然而问题是，对z进行积分很多情况下是非常困难的，特别是z的维数可能与样本量一样大，这个时候如果计算数值积分是非常恐怖的一件事情**。

&nbsp;
## 三、极大似然估计与最大后验概率估计：
### 1.频率学派： 
**他们认为世界是确定的**。他们直接为事件本身建模，也就是说事件在多次重复实验中趋于一个稳定的值p，那么这个值就是该事件的概率。 
他们认为模型参数是个定值，希望通过类似解方程组的方式从数据中求得该未知数。这就是频率学派使用的参数估计方法-极大似然估计（MLE），这种方法往往在大数据量的情况下可以很好的还原模型的真实情况。 
### 2.贝叶斯派： 
**他们认为世界是不确定的**，因获取的信息不同而异。假设对世界先有一个预先的估计，然后通过获取的信息来不断调整之前的预估计。  
他们不试图对事件本身进行建模，而是从旁观者的角度来说。因此对于同一个事件，不同的人掌握的先验不同的话，那么他们所认为的事件状态也会不同。 

贝叶斯派视角下用来估计参数的常用方法-最大后验概率估计（MAP），这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。**极端情况下，比如把先验假设去掉，或者假设先验满足均匀分布的话，那她和极大似然估计就如出一辙了**。 

&nbsp;
## reference
[详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解](https://blog.csdn.net/u011508640/article/details/72815981)  
[最大似然估计，最大后验估计，贝叶斯估计联系与区别](https://blog.csdn.net/bitcarmanlee/article/details/81417151)  
[最最大似然估计和EM算法的关系是什么？ - 慧航的回答 - 知乎](https://www.zhihu.com/question/22371861/answer/80954382)
