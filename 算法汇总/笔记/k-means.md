## K-means,K-means++,ISODATA和Kernel K-means：   
### 1）.K-means与K-means++：  
原始K-means算法最开始随机选取数据集中K个点作为聚类中心;  


而K-means++,其实这个算法也只是对初始点的选择有改进而已，其他步骤都一样。初始质心选取的基本思路就是，初始的聚类中心之间的相互距离要尽可能的远。   
算法描述如下：  
```
步骤一：随机选取一个样本作为第一个聚类中心 c1；

步骤二：计算每个样本与当前已有类聚中心最短距离（即与最近一个聚类中心的距离），用 D(x)表示；
这个值越大，表示被选取作为聚类中心的概率较大；最后，用轮盘法选出下一个聚类中心；

步骤三：重复步骤二，知道选出 k 个聚类中心。
选出初始点后，就继续使用标准的 k-means 算法了。
```
其实这个算法也只是对初始点的选择有改进而已，其他步骤都一样。初始质心选取的基本思路就是，初始的聚类中心之间的相互距离要尽可能的远。

### 2）.当遇到高维度、海量的数据集时，人们往往很难准确地估计出K的大小。  
ISODATA就是针对这个问题进行了改进，它的思想也很直观：当属于某个类别的样本数过少时把这个类别去除，当属于某个类别的样本数过多、分散程度较大时把这个类别分为两个子类别。 

### 3）.Kernel K-means：  
传统K-means采用欧式距离进行样本间的相似度度量，显然并不是所有的数据集都适用于这种度量方式。  
参照支持向量机中核函数的思想，将所有样本映射到另外一个特征空间中再进行聚类，就有可能改善聚类效果。 
