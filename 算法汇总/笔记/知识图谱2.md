因为知识图谱的数据源可能有多个，在不同数据源有对同一实体的不同表达，即使在同一个数据源里也可能存在这种情况，需要通过一定手段将其合并。

RDF形式上表示为SPO三元组，RDFS和OWL在表现形式上就是rdf。   
RDF的表达能力有限，无法区分类和对象，也无法定义和描述类的关系/属性.    
RDFS和OWL这两种技术或者说模式语言/本体语言（schema/ontology language）解决了RDF表达能力有限的困境.

RDFS/OWL本质上是一些预定义词汇（vocabulary）构成的集合，用于对RDF进行类似的类定义及其属性的定义。
RDFS本质上是RDF词汇的一个扩展。可以把OWL当做是RDFS的一个扩展，其添加了额外的预定义词汇。

### RDF序列化方法
RDF的表示形式和类型有了，那我们如何创建RDF数据集，将其序列化（Serialization）呢？换句话说，就是我们怎么存储和传输RDF数据。   
目前，RDF序列化的方式主要有：RDF/XML（用xml的格式表示），N-Triples（多个三元组，如DBpe dia），Turtle（使用最多，比RDF/XML紧凑，可读性比N-Triples好），RDFa，JSON-LD（json for linking data ，用键值对表示rdf ）等几种。

#### 上下位关系是语言学概念。概括性较强的单词叫做特定性较强的单词的上位词（hypernym），特定性较强的单词叫做概括性较强的单词的下位词(hyponym)。
例如， 猩红色、鲜红色、胭脂红、绯红色都是“红色 ”的下位词，而红色则是猩红色的上位词。

&nbsp;
### 表示学习
旨在将研究对象的语义信息表示为稠密低维实值向量，知识表示学习主要是面向知识图谱中的实体和关系进行表示学习。      
使用建模方法将实体和关系表示在低维稠密向量空间中，然后进行计算和推理。    
简单来说，就是将三元组表示成向量的这个过程就称为表示学习，而我们今天介绍的就是【Trans系列】中的一个经典方法【TransE模型】。

知识表示的几个代表模型：翻译模型、距离模型、单层神经网络模型、能量模型、双线性模型、张量神经网络模型、矩阵分解模型等。
TransE模型属于翻译模型：直观上，将每个三元组实例（head，relation，tail）中的关系relation看做从实体head到实体tail的翻译，通过不断调整h、r 和 t（head、relation和tail的向量），使（h + r） 尽可能与 t 相等，即 h + r = t

**TransE 是基于实体和关系的分布式向量表示，由 Bordes 等人于2013年提出，受word2vec启发，利用了词向量的【平移不变现象】**。   
例如：C(king)−C(queen)≈C(man)−C(woman)   其中，C(w)就是word2vec学习到的词向量表示。
TransR/CTransR


### Falcon-AO:自动的本体匹配系统（java语言）
V-Doc：基于虚拟文档的语言学匹配，它是将实体及其周围的实体、名词、文本等信息作一个集合形成虚拟文档的形式。这样我们就可以用TD-IDF等算法进行操作（使用向量空间模型计算虚拟文档的相似性）。
I-Sub：基于编辑距离的字符串匹配；
GMO：基于本体RDF图结构的匹配；
PBM:基于分而治之的大本体匹配。
流程：PBM--V-Doc、I-Sub--GMO
GMO：graph match for ontology基于图结构的本体匹配方案，使用RDF二部图表示本体，通过递归传播相似性来计算实体和三元组之间的结构相似性。一般用V-Doc和I-Sub的输出作为它的输入。

### 实体匹配：
Dedupe：一个用于模糊匹配、记录去重和实体链接的python库
1）.指定谓词集合、相似度函数
2）.训练Blocking：通过Red-Blue set cover找到最优谓词集合来分块
3）.用用户标记的正负样本对训练LR（逻辑回归）模型，进行分类。不确定的返回给用户标注。

### Limes：基于度量空间的实体匹配发现框架，适合大规模数据链接（java）
流程：给定源数据极S，目标数据集T，阈值
1）.样本选取：从T中选取样本点E来代表T中数据。
样本点要能代表距离空间，应分布均匀、各样本之间距离尽可能大。
2）.过滤：计算S、E之间的距离，利用三角不等式进行过滤
3）.相似度计算：同上
4）.序列化：存储为指定格式。

Tutorial：使用Limes进行实体关系融合的关键步骤是写好配置文件，包括数据源、融合算法、融合条件等信息。

Metric使用实例：余弦相似度、完全匹配（ExactMatch，非常严格的相似度比较算法，Review为0，精确度很高但召回率很低）相似度。

TransE模型属于翻译模型：直观上，将每个三元组实例（head，relation，tail）中的关系relation看做从实体head到实体tail的翻译，通过不断调整h、r 和 t（head、relation和tail的向量），使（h + r） 尽可能与 t 相等，即 h + r = t 
TransE 是基于实体和关系的分布式向量表示，由 Bordes 等人于2013年提出，受word2vec启发，利用了词向量的【平移不变现象】



### Silk：一个集成异构数据源的开源框架（python）
流程：
1）.预处理：将索引结果排名前N的作为候选对，进行下一步匹配。
2）.相似度计算：包含很多相似度计算方法。
3）.过滤：过滤掉相似度小于给定阈值的记录对。
特点：专门的Silk-LSL语言、图形化界面。




技术流程，本体对齐和实体匹配流程基本相似：
1.数据预处理：语法正则化，数据正则化。
2.记录链接：先计算属性相似度，再计算实体相似度。
1）计算属性相似度：编辑距离，集合相似度计算（jaccard ，dice），基于向量的相似度计算（余弦相似度，tfidf 相似度）……
2）计算实体相似度：属性相似度如下
［sim(x1,y1),...,sim(xn,yn)］
21）聚合（最关键的问题是要生成训练集合）：
加权平均：w1*sim(x1,y1)+...+wn*sim(xn,yn)
手动制定规则:sim(x1,y1)>T1 and/or sim(xn,yn)>Tn
分类器：LR，决策树，SVM，CRF
22）聚类：
221)层次聚类（三种算法：距离最近的两个数据点间的相似度作为两个类的距离，距离最远……，所有点相似度的均值）：计算不同类别数据点之间的相似度对在不同的层次的数据进行划分，形成树状的聚类结构；
222)相关性聚类：rxy 表示xy被分在同一类，切断xy 边的代价，保留边的代价，使用最小代价找到一个聚类方案，是np-hard问题，用贪婪算法求近似解。
223)canopy+k-means
23）表示学习：知识嵌入
将实体和关系映射到低维向量空间，用数学表达式计算相似度，h+r=t。

如何将两个图谱嵌入同一个空间：
桥梁：预链接实体对（训练数据），
方法：1.联合知识嵌入：两个图谱三元组糅合训练，将预链接实体对视为sameas三元组，从而对图谱的空间进行约束：
2.双向监督训练：两个图谱单独训练，使用预链接数据交替进行监督。

如何链接实体：图谱向量训练稳定后，对图谱1中未找到链接的实体，计算图谱2中最近距离进行链接


分块：选出潜在匹配记录对
1.基于hash函数分块：字符串的前n个字、n-gram、结合多个简单的hash函数等
2.邻近分块：canopy聚类、排序邻居算法、red-blue set cover
负载均衡：保证块中实体数目相当，最简单的方法是多次map-reduce 操作

结果评估：准确率，召回率，f值，整个算法运行时间
