## xgboost版本较老
```
import pandas as pd  
feature_important = model.booster().get_score(importance_type='weight')  
keys = list(feature_important.keys())  
values = list(feature_important.values())  
data = pd.DataFrame({'feature': keys, 'score': values})  

data_sort=data.sort_values(by=['score'], axis=0, ascending=False, inplace=False)  
print data_sort.head()  
```
## xgboost非老版本
无需添加 **.booster()** 方法  


## 实例
1.获取前20个重要特征及其重要性  
```
importances=gbm.feature_importances_  
indices=np.argsort(importances)[::-1] #[::-1]倒序  
print (indices)  
for f in range(21):  
    print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))  

1. feature 2430 (0.056456)   
2. feature 2415 (0.039252)  
3. feature 1786 (0.026693)  
```
2.查看特征重要性（顺序）  
```
importances=gbm.feature_importances_  
indices=np.argsort(importances) #排序  
for f in range(10):  
    print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))  
    
print("feature %d (%f)" % (indices[3106], importances[indices[3106]]))
```
## reference
[Feature Importance with XGBClassifier](https://stackoverflow.com/questions/38212649/feature-importance-with-xgbclassifier)
